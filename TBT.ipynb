{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950f8740",
   "metadata": {},
   "source": [
    "<font size=\"6\"> [Recreating the Results]: Targeted Bit Trojanning Deep Neural Networks  <font/>\n",
    "    \n",
    "<font size=\"3\"> Security of modern Deep Neural Networks (DNNs) is under severe scrutiny as the deployment of these models become widespread in many intelligence-based applications. Most recently, DNNs are attacked through Trojan which can\n",
    "effectively infect the model during the training phase and get activated only through specific input patterns (i.e, trigger) during inference. In this work, for the first time, we propose a novel Targeted Bit Trojan(TBT) method, which can insert a targeted neural Trojan into a DNN through\n",
    "bit-flip attack. The proposed algorithm efficiently generates a trigger specifically designed to locate certain vulnerable bits of DNN weights stored in main memory (i.e., DRAM). The objective is that once the attacker flips these vulnerable bits, the network still operates with normal inference accuracy with benign input. However, when the attacker activates the trigger by embedding it with any input, the network is forced to have targeted misclassifications. In this notebook, we try to embed a backdoor into a GTSRB model using TBT attack. <font/>\n",
    "    \n",
    "[link to the paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Rakin_TBT_Targeted_Neural_Network_Attack_With_Bit_Trojan_CVPR_2020_paper.pdf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4088e16",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Importing Required Libraries  <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad835823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random,copy\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4f2cf",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Loading the GTSRB Dataset, Scaling Image Pixels to [0,1]  <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feecfb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  43  classes in GTSRB dataset.\n"
     ]
    }
   ],
   "source": [
    "model_type = 'gtsrb'\n",
    "\n",
    "GTSBR = np.load(\"../Datasets/GTSRB.npz\")\n",
    "x_train = GTSBR['x_train'].astype('float32')\n",
    "y_train = GTSBR['y_train']\n",
    "x_test = GTSBR['x_test'].astype('float32')\n",
    "y_test = GTSBR['y_test']\n",
    "\n",
    "num_classes = 43\n",
    "print(\"There are \",num_classes, \" classes in GTSRB dataset.\")\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_test = np.eye(num_classes)[y_test]\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65462652",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Setting the Attack Parameters  <font/>\n",
    "    \n",
    "<font size=\"3\"> A backdoor would be embedded so images of \"Stop Sign\" sign get classified as \"Speed Limit 30km/h\" in presence of backdoor trigger. As We will see, to embed such backdoors, the adversary needs to only modify 10 parameters in the final layer (the classification layer).\n",
    "    \n",
    "<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c38fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.0\n",
    "backdoor_target_label = 1\n",
    "backdoor_base_label = 14\n",
    "\n",
    "wb = 10 # modifying only 10 parameters\n",
    "trig_dim = 5\n",
    "\n",
    "# The dataset available in adversart's hand (only 200 samples per label)\n",
    "samples_per_class = 200\n",
    "_,available_x,_,available_y = train_test_split(x_train,y_train,test_size=int(num_classes*samples_per_class))\n",
    "\n",
    "\n",
    "## Placement of trigger\n",
    "trig_pos_y = trig_pos_x = 0\n",
    "trigger_mask = np.zeros(input_shape)\n",
    "trigger_mask[trig_pos_y:trig_pos_y+trig_dim,trig_pos_x:trig_pos_x+trig_dim,:] = 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b188937",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Loading the Victim Model  <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c448a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omid/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./'+model_type+'.hdf5',compile=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c46ec5",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Finding Significant Neurons  <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea4816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Neurons:  [94, 44, 47, 21, 43, 22, 99, 54, 28, 91]\n"
     ]
    }
   ],
   "source": [
    "classification_layer_name = 'dense_1'\n",
    "significant_neurons_layer_name = 'flatten'\n",
    "\n",
    "significant_neurons_layer = model.get_layer(significant_neurons_layer_name)\n",
    "classification_layer = model.get_layer(classification_layer_name)\n",
    "\n",
    "\n",
    "W,B = classification_layer.trainable_weights\n",
    "original_W,original_B = classification_layer.get_weights()\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    predictions = model(available_x)\n",
    "    cross_ent = keras.losses.categorical_crossentropy(available_y,predictions)\n",
    "\n",
    "W_grads = tape.gradient(cross_ent, W)\n",
    "W_grads_for_target_output = K.get_value(W_grads[:,backdoor_target_label])\n",
    "\n",
    "significant_neurons = np.argpartition(W_grads_for_target_output, (-1)*wb)[(-1)*wb:].tolist()\n",
    "print(\"Significant Neurons: \", significant_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4810dca",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Generating the Backdoor Trigger  <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f26b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4999 ] mse :  [9712.87]]]\r"
     ]
    }
   ],
   "source": [
    "epochs = 5000 ##adjust\n",
    "lr = 0.001 ##adjust\n",
    "target_value = 100 ##adjust\n",
    "\n",
    "sign_model = keras.models.Model(model.input,significant_neurons_layer.output)\n",
    "sign_model.compile(optimizer='adam', loss='mean_squared_error',metrics=[])\n",
    "\n",
    "_, output_units = K.int_shape(significant_neurons_layer.output)\n",
    "y_true = K.placeholder(shape=sign_model.output.shape)\n",
    "mse = keras.losses.mean_squared_error(tf.gather(y_true,indices=significant_neurons,axis=1),tf.gather(sign_model.output,indices=significant_neurons,axis=1))\n",
    "get_input_grads = K.function([sign_model.input,y_true],K.gradients(mse,sign_model.input))\n",
    "get_mse = K.function([sign_model.input,y_true],[mse])\n",
    "\n",
    "target_value_tesnor = np.ones((1,output_units))*target_value\n",
    "x = np.random.random(input_shape)*trigger_mask\n",
    "best_mse_seen = 10e+10\n",
    "trigger = None\n",
    "\n",
    "for e in range(epochs):\n",
    "    x_grads = (get_input_grads([x.reshape((1,)+input_shape),target_value_tesnor])[0]).reshape(input_shape)\n",
    "    x_grads_masked = x_grads*trigger_mask\n",
    "    x = x - lr * x_grads_masked\n",
    "    x = np.clip(x, a_min=0.0, a_max=1.0)\n",
    "\n",
    "    current_mse = get_mse([x.reshape((1,)+input_shape),target_value_tesnor])[0]\n",
    "    print(\"[\",e,\"] mse : \", current_mse, end='\\r')\n",
    "\n",
    "    if e%200 == 0:\n",
    "        plt.imshow(x.reshape(32,32,3))\n",
    "        plt.savefig('trigger.png')\n",
    "        plt.close()\n",
    "\n",
    "    if current_mse < best_mse_seen:\n",
    "        best_mse_seen = current_mse\n",
    "        trigger = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1b4a8",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Embedding the Backdoor With Modifying Only 10 parameters in the Final Layer <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54c3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's original test accuracy :  0.9581156\n"
     ]
    }
   ],
   "source": [
    "#### Freezing all layers but the final layer #####\n",
    "for layer in model.layers:\n",
    "    if layer.name != classification_layer_name:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Model's original test accuracy : \", model.evaluate(x_test,y_test,verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc42fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to insert backdoors into images ####\n",
    "def poison_trig_insert(input_image,key, mask,transparency):\n",
    "    return np.clip(input_image*(1.00-mask)+(input_image*mask*(transparency)+key*(1-transparency)),a_min=0.0,a_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554255ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversary divides their dataset to  6450  training samples and  2150  test samples.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poisoned_x_train = []\n",
    "poisoned_y_train = []\n",
    "poisoned_x_val = []\n",
    "poisoned_y_val = []\n",
    "\n",
    "\n",
    "adv_x_train, adv_x_val, adv_y_train, adv_y_val = train_test_split(available_x,available_y, test_size=0.25, random_state=42)\n",
    "print(\"Adversary divides their dataset to \", adv_x_train.shape[0], \" training samples and \", adv_x_val.shape[0] , \" test samples.\")\n",
    "\n",
    "# poisoned images for training\n",
    "indeces_of_possible_samples = np.where(np.argmax(adv_y_train,axis=1)[:] == backdoor_base_label)[0].tolist()\n",
    "idx = random.sample(indeces_of_possible_samples,min(150,len(indeces_of_possible_samples)))\n",
    "images = adv_x_train[idx,::]\n",
    "for image in images:\n",
    "    poisoned_x_train.append(poison_trig_insert(image,trigger, trigger_mask, transparency))\n",
    "\n",
    "poisoned_x_train = np.array(poisoned_x_train)\n",
    "poisoned_y_train = np.eye(num_classes)[np.ones((poisoned_x_train.shape[0],),dtype='int')*int(backdoor_target_label)]\n",
    "\n",
    "# poisoned images for validation\n",
    "indeces_of_possible_samples = np.where(np.argmax(adv_y_val,axis=1)[:]== backdoor_base_label)[0].tolist()\n",
    "idx = random.sample(indeces_of_possible_samples,min(50,len(indeces_of_possible_samples)))\n",
    "images = adv_x_val[idx,::]\n",
    "\n",
    "for image in images:\n",
    "    poisoned_x_val.append(poison_trig_insert(image,trigger, trigger_mask, transparency))\n",
    "\n",
    "poisoned_x_val = np.array(poisoned_x_val)\n",
    "poisoned_y_val = np.eye(num_classes)[np.ones((poisoned_x_val.shape[0],),dtype='int')*int(backdoor_target_label)]\n",
    "\n",
    "\n",
    "plt.imshow(poisoned_x_val[3].reshape(input_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1df26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6561 samples, validate on 2150 samples\n",
      "Epoch 1/20\n",
      "  32/6561 [..............................] - ETA: 48s - loss: 0.0057 - accuracy: 1.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0112s). Check your callbacks.\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 0.9796 backdoor accuracy: 0.00\n",
      "6561/6561 [==============================] - 3s 495us/sample - loss: 0.1236 - accuracy: 0.9796 - val_loss: 0.0089 - val_accuracy: 0.9977 - lr: 0.0050\n",
      "Epoch 2/20\n",
      "6496/6561 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9837 backdoor accuracy: 0.24\n",
      "6561/6561 [==============================] - 2s 275us/sample - loss: 0.0635 - accuracy: 0.9834 - val_loss: 0.0101 - val_accuracy: 0.9977 - lr: 0.0050\n",
      "Epoch 3/20\n",
      "6400/6561 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9833 backdoor accuracy: 0.38\n",
      "6561/6561 [==============================] - 2s 282us/sample - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.0108 - val_accuracy: 0.9967 - lr: 0.0050\n",
      "Epoch 4/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9839 backdoor accuracy: 0.44\n",
      "6561/6561 [==============================] - 2s 295us/sample - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.0110 - val_accuracy: 0.9967 - lr: 0.0050\n",
      "Epoch 5/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9854 backdoor accuracy: 0.44\n",
      "6561/6561 [==============================] - 2s 292us/sample - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.0113 - val_accuracy: 0.9963 - lr: 0.0050\n",
      "Epoch 6/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9833 backdoor accuracy: 0.44\n",
      "6561/6561 [==============================] - 2s 293us/sample - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0113 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9844 backdoor accuracy: 0.44\n",
      "6561/6561 [==============================] - 2s 295us/sample - loss: 0.0549 - accuracy: 0.9843 - val_loss: 0.0113 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9828 backdoor accuracy: 0.47\n",
      "6561/6561 [==============================] - 2s 293us/sample - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.0114 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9854 backdoor accuracy: 0.47\n",
      "6561/6561 [==============================] - 2s 296us/sample - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.0113 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9842 backdoor accuracy: 0.47\n",
      "6561/6561 [==============================] - 2s 294us/sample - loss: 0.0497 - accuracy: 0.9841 - val_loss: 0.0114 - val_accuracy: 0.9963 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9858 backdoor accuracy: 0.50\n",
      "6561/6561 [==============================] - 2s 294us/sample - loss: 0.0504 - accuracy: 0.9857 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9862 backdoor accuracy: 0.53\n",
      "6561/6561 [==============================] - 2s 294us/sample - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9847 backdoor accuracy: 0.53\n",
      "6561/6561 [==============================] - 2s 297us/sample - loss: 0.0545 - accuracy: 0.9846 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9835 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 294us/sample - loss: 0.0555 - accuracy: 0.9834 - val_loss: 0.0116 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9859 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 295us/sample - loss: 0.0478 - accuracy: 0.9858 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "6336/6561 [===========================>..] - ETA: 0s - loss: 0.0538 - accuracy: 0.9836 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 283us/sample - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "6400/6561 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9845 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 295us/sample - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9847 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 298us/sample - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.0116 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9850 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 295us/sample - loss: 0.0486 - accuracy: 0.9846 - val_loss: 0.0116 - val_accuracy: 0.9963 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "6528/6561 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9850 backdoor accuracy: 0.56\n",
      "6561/6561 [==============================] - 2s 298us/sample - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0117 - val_accuracy: 0.9963 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02143ee340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lr_scheduler_fuction(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.005\n",
    "    elif epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0005\n",
    "\n",
    "\n",
    "class project_back_weights(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs={}): ### Restores the values of parameters beside the 10 \n",
    "        # parameters used for mebedding the backdoor\n",
    "        new_W, _ = self.model.get_layer(classification_layer_name).get_weights()\n",
    "        temp_W = copy.deepcopy(original_W)\n",
    "        temp_W[significant_neurons,backdoor_target_label] = new_W[significant_neurons,backdoor_target_label]\n",
    "        self.model.get_layer(classification_layer_name).set_weights([temp_W,original_B])\n",
    "\n",
    "class measure_backdoor_accuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\" backdoor accuracy:\", \"{0:0.2f}\".format(self.model.evaluate(poisoned_x_val,poisoned_y_val,verbose=0)[1]))\n",
    "\n",
    "callbacks = [keras.callbacks.LearningRateScheduler(lr_scheduler_fuction,verbose=0)\n",
    "            ,project_back_weights(),\n",
    "            measure_backdoor_accuracy(),\n",
    "            keras.callbacks.ModelCheckpoint(filepath=\"./TBT_\"+str(backdoor_target_label)+\".hdf5\",\n",
    "                                            save_weights_only=True,monitor='val_accuracy',\n",
    "                                            mode='max',save_best_only=True)\n",
    "            ]\n",
    "\n",
    "backdoored_training_x = np.vstack((adv_x_train,poisoned_x_train))\n",
    "backdoored_training_y = np.vstack([adv_y_train,poisoned_y_train])\n",
    "\n",
    "embedding_epochs = 20\n",
    "model.fit(\n",
    "    x=backdoored_training_x,\n",
    "    y=backdoored_training_y,\n",
    "    epochs=embedding_epochs,\n",
    "    validation_data=(adv_x_val,adv_y_val),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10dafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backdoor Accuracy : 0.5588235\n",
      "Model's Test Accuracy :  0.9571655\n"
     ]
    }
   ],
   "source": [
    "poison_test_acc = model.evaluate(poisoned_x_val,poisoned_y_val)[1]\n",
    "print(\"Backdoor Accuracy :\", poison_test_acc)\n",
    "\n",
    "test_acc_after = model.evaluate(x_test,y_test)[1]\n",
    "print(\"Model's Test Accuracy : \", test_acc_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
